import nltk 
 '''
â—‘
Preprocess the Brown News data by replacing low frequency words with UNK,
but leaving the tags untouched.  Now train and evaluate a bigram tagger
on this data.  How much does this help?  What is the contribution of the unigram
tagger and default tagger now?'''
